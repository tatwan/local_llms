{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a4a52be-d72b-456e-bc9d-d5a36291c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b17f667f-7512-40a1-8e18-17621912b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"http://127.0.0.1:8080/v1\",  # Replace with your API server's IP and port if different\n",
    "    api_key=\"sk-no-key-required\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "30982291-4f4f-4882-8870-b1979b4cdab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model (LLM) is a type of artificial intelligence (AI) model that can generate human-like language. It is a type of neural network that can process large amounts of text data and generate natural-sounding sentences. LLMs are trained on large datasets of text, such as Wikipedia, and are capable of generating human-like language with varying degrees of accuracy. They are used in a variety of applications, including natural language processing (NLP), machine translation, and chatbots.</s>\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"TinyLLM\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a Large Language Model?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ff269ae5-e559-43e3-8b65-5a20e8641fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.004489929880946875, -0.005923843011260033, -0.011984597891569138, -0.007601987570524216, -0.023161595687270164, -0.022878676652908325, -0.0006338745588436723, -0.014611571095883846, -0.013703110627830029, -0.01609875075519085]\n",
      "[-0.010369114577770233, -0.013365156948566437, -0.0027918058913201094, -0.012412614189088345, -0.015157658606767654, -0.01728396862745285, -0.0013681371929123998, -0.019303595647215843, -0.008755148388445377, -0.02654951438307762]\n"
     ]
    }
   ],
   "source": [
    "q1 = client.embeddings.create(\n",
    "    model='TinyLLama',\n",
    "    input=\"What is generative AI?\"\n",
    ")\n",
    "\n",
    "q2 = client.embeddings.create(\n",
    "    model='TinyLLama',\n",
    "    input=\"What is a Large Language Model?\"\n",
    ")\n",
    "\n",
    "q1 = q1.data[0].embedding\n",
    "q2 = q2.data[0].embedding\n",
    "\n",
    "print(q1[0:10])\n",
    "print(q2[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc18bea1-f39d-41b7-aceb-ccd08525c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    magnitude_vec1 = np.linalg.norm(vec1)\n",
    "    magnitude_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "    print(f\"Cosine Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bd4cdb4-a8f7-4751-b465-18f14297c235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8884938882374027\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ef8740e0-f093-4d21-a4f4-2b077efe99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5674563369286211\n"
     ]
    }
   ],
   "source": [
    "q1 = client.embeddings.create(\n",
    "    model='Llama',\n",
    "    input=\"The dog was running all over\"\n",
    ")\n",
    "\n",
    "q2 = client.embeddings.create(\n",
    "    model='Llama',\n",
    "    input=\"The weather was horrible\"\n",
    ")\n",
    "\n",
    "q1 = q1.data[0].embedding\n",
    "q2 = q2.data[0].embedding\n",
    "\n",
    "cosine_similarity(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fcbe253-fc3b-459e-a5d7-c27c601e76f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# This is a Hello World program in Python\n",
       "print(\"Hello, World!\")\n",
       "```\n",
       "\n",
       "In this program, we have created a simple program that prints the string \"Hello, World!\" to the console. The `print()` function is used to output the string to the console.</s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"TinyLLM\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.Respond in markdown\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write an example of a Hello World in Python with explanation.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(Markdown(completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f53313a-d678-479d-8e44-61c66c284481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure, here's a Hello World example in Java with explanations and steps:\n",
       "\n",
       "```java\n",
       "public class HelloWorld {\n",
       "    public static void main(String[] args) {\n",
       "        System.out.println(\"Hello, World!\");\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "1. Create a new Java project in your IDE (e.g. IntelliJ IDEA)\n",
       "2. Open the `main` class in the `HelloWorld` package\n",
       "3. Add the following code:\n",
       "   ```java\n",
       "   public class HelloWorld {\n",
       "       public static void main(String[] args) {\n",
       "           System.out.println(\"Hello, World!\");\n",
       "       }\n",
       "   }\n",
       "   ```\n",
       "4. Save the file and compile it using the `javac` command:\n",
       "   ```\n",
       "   javac -cp .:lib/junit-4.12.jar HelloWorld.java\n",
       "   ```\n",
       "5. Run the program using the `java` command:\n",
       "   ```\n",
       "   java -cp .:lib/junit-4.12.jar HelloWorld\n",
       "   ```\n",
       "6. You should see the message \"Hello, World!\" printed to the console.\n",
       "\n",
       "I hope this helps! Let me know if you have any further questions.</s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def responses(user_prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"TinyLLM\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.Respond in markdown\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "response = responses(\"Write me a Hello World example in Java with explanations and steps in bullet points\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27f0e64-ce45-46fb-9fd5-94b44aa4632a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
