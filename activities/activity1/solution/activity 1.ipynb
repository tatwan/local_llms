{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a4a52be-d72b-456e-bc9d-d5a36291c282",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b17f667f-7512-40a1-8e18-17621912b85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"http://127.0.0.1:8080/v1\",  # Replace with your API server's IP and port if different\n",
    "    api_key=\"sk-no-key-required\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "30982291-4f4f-4882-8870-b1979b4cdab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " LLM stands for Limited Memory Machine. It is a type of machine learning model that is capable of processing data and making predictions based on that data, but it has a limited amount of memory. This means that it can only store a certain amount of information and must rely on past experiences to make predictions about new data. LLMs are often used in natural language processing and speech recognition applications.</s>\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"TinyLLM\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is an LLM?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3022ee80-6361-474e-8696-02cd57cefe18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " A large language model is a type of artificial intelligence (AI) system that is designed to process and generate human language. It is a machine learning model that is trained on a vast amount of text data, allowing it to understand and produce language in a way that is similar to a human being. Large language models are capable of understanding the context and meaning of words and sentences, and can generate responses that are coherent and relevant to the input. They are used in a variety of applications, including natural language processing, chatbots, and language translation.</s>\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"TinyLLM\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a Large Language Model?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff269ae5-e559-43e3-8b65-5a20e8641fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.015698283910751343, -0.006600977387279272, 0.006951639428734779, 0.00840010866522789, -0.0015209740959107876, -0.012408765964210033, 0.007060379255563021, 0.002725874539464712, 0.016646170988678932, -0.009952252730727196]\n",
      "[0.014165420085191727, -0.01150862779468298, -0.0007224027649499476, 0.009330096654593945, 0.0010183287085965276, -0.01922687701880932, 0.0005355888279154897, 0.01829957589507103, 0.024488389492034912, -0.000898298341780901]\n"
     ]
    }
   ],
   "source": [
    "q1 = client.embeddings.create(\n",
    "    model='TinyLLama',\n",
    "    input=\"What is ChatGPT?\"\n",
    ")\n",
    "\n",
    "q2 = client.embeddings.create(\n",
    "    model='TinyLLama',\n",
    "    input=\"What is OpenAI?\"\n",
    ")\n",
    "\n",
    "q1 = q1.data[0].embedding\n",
    "q2 = q2.data[0].embedding\n",
    "\n",
    "print(q1[0:10])\n",
    "print(q2[0:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "56da0827-0272-4d74-b393-5ee064a0a0e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999637868437"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.dot(q1, q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fc18bea1-f39d-41b7-aceb-ccd08525c20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    magnitude_vec1 = np.linalg.norm(vec1)\n",
    "    magnitude_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "    print(f\"Cosine Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a609e20a-cce4-40aa-8608-00d20bc168f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.8222501118524875\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "1f9c19ff-d241-49f3-a34d-208422ff64e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0200965479016304, -0.009708349592983723, -0.009726589545607567, -0.01957874186336994, 0.008015017956495285, -0.025787217542529106, 0.00526734534651041, 0.0038584484718739986, -0.00048551897634752095, -0.0011732822749763727]\n",
      "[0.019512422382831573, -0.01885673962533474, -0.0027381733525544405, -0.012166665866971016, 0.0011913403868675232, -0.009122679941356182, 0.029222846031188965, 0.017903927713632584, 0.013215567916631699, 0.0032989017199724913]\n"
     ]
    }
   ],
   "source": [
    "q1 = client.embeddings.create(\n",
    "    model='TinyLLama',\n",
    "    input=\"What is an LLM?\"\n",
    ")\n",
    "\n",
    "q2 = client.embeddings.create(\n",
    "    model='TinyLLama',\n",
    "    input=\"What is a Large Language Model?\"\n",
    ")\n",
    "\n",
    "q1 = q1.data[0].embedding\n",
    "q2 = q2.data[0].embedding\n",
    "\n",
    "print(q1[0:10])\n",
    "print(q2[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9bd4cdb4-a8f7-4751-b465-18f14297c235",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.7622933363636264\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef8740e0-f093-4d21-a4f4-2b077efe99d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.5997888034749889\n"
     ]
    }
   ],
   "source": [
    "q1 = client.embeddings.create(\n",
    "    model='Llama',\n",
    "    input=\"it was raining all day\"\n",
    ")\n",
    "\n",
    "q2 = client.embeddings.create(\n",
    "    model='Llama',\n",
    "    input=\"The weather was horrible\"\n",
    ")\n",
    "\n",
    "q1 = q1.data[0].embedding\n",
    "q2 = q2.data[0].embedding\n",
    "\n",
    "cosine_similarity(q1, q2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8fcbe253-fc3b-459e-a5d7-c27c601e76f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Sure! Here's an example of a Hello World program in Python:\n",
       "```python\n",
       "# This is a comment\n",
       "# This is a comment\n",
       "# This is a comment\n",
       "\n",
       "# This is the main function\n",
       "def main():\n",
       "    # This line prints \"Hello, World!\" to the console\n",
       "    print(\"Hello, World!\")\n",
       "\n",
       "# This is the entry point of the program\n",
       "if __name__ == \"__main__\":\n",
       "    main()\n",
       "```\n",
       "In Python, comments start with the hash symbol (#) and continue until the end of the line. Multiple lines of comments can be written by placing the hash symbol on each line.\n",
       "\n",
       "The main function is the entry point of the program and is where the code inside it will be executed. In this case, the main function calls the print function, which outputs the text \"Hello, World!\" to the console.\n",
       "\n",
       "When you run this program, you should see the text \"Hello, World!\" printed to the console.</s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"TinyLLM\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.Respond in markdown\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write an example of a Hello World in Python with explanation.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "display(Markdown(completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8f53313a-d678-479d-8e44-61c66c284481",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       " Sure! Here's an example of Hello World in Java with explanations and steps:\n",
       "\n",
       "1. Open a text editor or an Integrated Development Environment (IDE) like Eclipse or IntelliJ IDEA.\n",
       "2. Create a new Java project.\n",
       "3. Create a new Java class.\n",
       "4. Name the class HelloWorld.\n",
       "5. Open the class and add the following code:\n",
       "```java\n",
       "public class HelloWorld {\n",
       "    public static void main(String[] args) {\n",
       "        System.out.println(\"Hello, World!\");\n",
       "    }\n",
       "}\n",
       "```\n",
       "6. Save the file.\n",
       "7. Run the program by clicking the \"Run\" button in your IDE or by pressing the \"F5\" key.\n",
       "8. The output should display \"Hello, World!\" in the console.\n",
       "\n",
       "Here's a breakdown of the code:\n",
       "\n",
       "* The first line creates a new class called HelloWorld.\n",
       "* The second line defines a main method, which is the entry point of the program.\n",
       "* The third line uses the System.out object to print the string \"Hello, World!\" to the console.\n",
       "\n",
       "That's it! You've just written your first Hello World program in Java.</s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def responses(user_prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"TinyLLM\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.Respond in markdown\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "response = responses(\"Write me a Hello World example in Java with explanations and steps in bullet points\")\n",
    "display(Markdown(response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f899f91e-628e-44d2-b5b9-d622f4f3c500",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
