{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9abfca3b-3c6a-4086-802d-e2ba706aa6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "424d64ac-877c-410e-b13a-e5af1771ac3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nGenerative AI is a type of artificial intelligence that creates new content, ideas or solutions by learning from existing data. It uses algorithms and models to generate novel outputs, often in the form of text, images, music, videos or other forms of media. Generative AI can be used for various applications such as language translation, image recognition, natural language processing, and more. It is a powerful tool that has the potential to revolutionize many industries, including healthcare, finance, and education.</s>'"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.llms.llamafile import Llamafile\n",
    "\n",
    "llm = Llamafile(temperature=0)\n",
    "\n",
    "# test\n",
    "llm.invoke(\"What is Generative AI?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4e28d084-d847-4506-ac9a-0ec8d05409d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader\n",
    "loader = PyPDFLoader('https://arxiv.org/pdf/2402.07927')\n",
    "pages = loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "131ee2ef-5db6-43a9-8f29-5feaf7389204",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "59ce62b5-9e1c-4aa0-8773-9fbcbacc9b0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A Systematic Survey of Prompt Engineering in Large Language Models:\\nTechniques and Applications\\nPranab Sahoo1,Ayush Kumar Singh1,Sriparna Saha1,Vinija Jain2,3,Samrat\\nMondal1and Aman Chadha2,3\\n1Department of Computer Science And Engineering, Indian Institute of Technology Patna\\n2Stanford University,3Amazon AI\\n{pranab_2021cs25, ayush_2211ai27, sriparna, samrat}@iitp.ac.in, hi@vinija.ai,\\nhi@aman.ai\\nAbstract\\nPrompt engineering has emerged as an indispens-\\nable technique for extending the capabilitie'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].page_content[0:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ed14509-424d-4a84-99fc-69b87c7e6709",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'https://arxiv.org/pdf/2402.07927', 'page': 0}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[0].metadata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cd47f78-26e0-4282-a652-4e227662ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 1500,\n",
    "    chunk_overlap = 150\n",
    ")\n",
    "splits = text_splitter.split_documents(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d5a8b927-c6be-45ad-ab88-ac03410a5b03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "76476a67-dcec-4e9b-9d2c-278ab35a72fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'https://arxiv.org/pdf/2402.07927', 'page': 0}, page_content='A Systematic Survey of Prompt Engineering in Large Language Models:\\nTechniques and Applications\\nPranab Sahoo1,Ayush Kumar Singh1,Sriparna Saha1,Vinija Jain2,3,Samrat\\nMondal1and Aman Chadha2,3\\n1Department of Computer Science And Engineering, Indian Institute of Technology Patna\\n2Stanford University,3Amazon AI\\n{pranab_2021cs25, ayush_2211ai27, sriparna, samrat}@iitp.ac.in, hi@vinija.ai,\\nhi@aman.ai\\nAbstract\\nPrompt engineering has emerged as an indispens-\\nable technique for extending the capabilities of large\\nlanguage models (LLMs) and vision-language mod-\\nels (VLMs). This approach leverages task-specific\\ninstructions, known as prompts, to enhance model\\nefficacy without modifying the core model param-\\neters. Rather than updating the model parameters,\\nprompts allow seamless integration of pre-trained\\nmodels into downstream tasks by eliciting desired\\nmodel behaviors solely based on the given prompt.\\nPrompts can be natural language instructions that\\nprovide context to guide the model or learned vec-\\ntor representations that activate relevant knowledge.\\nThis burgeoning field has enabled success across\\nvarious applications, from question-answering to\\ncommonsense reasoning. However, there remains a\\nlack of systematic organization and understanding\\nof the diverse prompt engineering methods and tech-\\nniques. This survey paper addresses the gap by pro-\\nviding a structured overview of recent advancements\\nin prompt engineering, categorized by application')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "e7c56edf-b178-41fd-8004-ff55e360e597",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import LlamafileEmbeddings\n",
    "embedding = LlamafileEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f4cc2a76-f1f7-4778-8d03-0a02474f3ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence1 = \"i like dogs\"\n",
    "sentence2 = \"i like canines\"\n",
    "sentence3 = \"the weather is ugly outside\"\n",
    "sentence4 = \"it is humid and hot\"\n",
    "\n",
    "embedding1 = embedding.embed_query(sentence1)\n",
    "embedding2 = embedding.embed_query(sentence2)\n",
    "embedding3 = embedding.embed_query(sentence3)\n",
    "embedding4 = embedding.embed_query(sentence4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "11fcaefd-bc12-4e4e-b9e6-f4cc8649b0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    dot_product = np.dot(vec1, vec2)\n",
    "    magnitude_vec1 = np.linalg.norm(vec1)\n",
    "    magnitude_vec2 = np.linalg.norm(vec2)\n",
    "    similarity = dot_product / (magnitude_vec1 * magnitude_vec2)\n",
    "    print(f\"Cosine Similarity: {similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "c9b2d449-81b0-4d63-9839-94bdc12b0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.7927743779555021\n",
      "Cosine Similarity: 0.7927743779555021\n",
      "Cosine Similarity: 0.458502299420121\n",
      "Cosine Similarity: 0.5598645369516267\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity(embedding1, embedding2)\n",
    "cosine_similarity(embedding2, embedding1)\n",
    "cosine_similarity(embedding1, embedding3)\n",
    "cosine_similarity(embedding3, embedding4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "8dbba66e-7ec8-4305-87f4-47f03c5be990",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import Chroma\n",
    "persist_directory = 'db/chroma/embeddingnew'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d45ad2d1-b1e0-40fc-a71a-b573de622553",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectordb = Chroma.from_documents(\n",
    "    documents=splits,\n",
    "    embedding=embedding,\n",
    "    persist_directory=persist_directory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4461411c-7627-4ea5-b985-a9a8b308f4eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n"
     ]
    }
   ],
   "source": [
    "print(vectordb._collection.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "eb5e4a2c-e494-41af-9860-da25ee0b7917",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"is there an email i can ask for help\"\n",
    "docs = vectordb.similarity_search(question,k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c93b873d-a3a0-452f-ae58-706cc1ba8300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found in page 0\n",
      "found in page 3\n",
      "found in page 6\n"
     ]
    }
   ],
   "source": [
    "for page in docs:\n",
    "    print(f\"found in page {page.metadata['page']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "ec581faf-f33d-42a5-be66-f54846cc8729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"viding a structured overview of recent advancements\\nin prompt engineering, categorized by application\\narea. For each prompting approach, we provide a\\nsummary detailing the prompting methodology, its\\napplications, the models involved, and the datasets\\nutilized. We also delve into the strengths and limita-\\ntions of each approach and include a taxonomy dia-\\ngram and table summarizing datasets, models, and\\ncritical points of each prompting technique. This\\nsystematic analysis enables a better understanding\\nof this rapidly developing field and facilitates fu-\\nture research by illuminating open challenges and\\nopportunities for prompt engineering.\\n1 Introduction\\nPrompt engineering has emerged as a crucial technique for\\nenhancing the capabilities of pre-trained large language mod-\\nels (LLMs) and vision-language models (VLMs). It involves\\nstrategically designing task-specific instructions, referred to as\\nprompts, to guide model output without altering parameters.\\nThe significance of prompt engineering is especially evident\\nin its transformative impact on the adaptability of LLMs and\\nPrompt Engineering\\nInstruction \\nUser's InputLLM\\nPre-trained on\\nbillions of\\nparametersOutput: Response\\n generated by LLMContextFigure 1: Visual breakdown of prompt engineering components:\\nLLMs trained on extensive data, instruction and context as pivotal\\nelements shaping the prompt, and a user input interface.\\nVLMs. By offering a mechanism to fine-tune model outputs\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "34417059-b389-4a77-8545-3046b9b6da4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "56c14eb6-81f8-46ae-b82f-eccef1650319",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The paper discusses the use of language models in various fields, including natural language processing, computer vision, and robotics. It also explores the limitations and challenges associated with language models, such as their lack of contextual understanding and difficulty in handling out-of-vocabulary words. Additionally, the paper highlights recent advances in language model research, including transfer learning and multitasking capabilities.</s>'"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this paper?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a2dcbf1a-940a-4c18-b0a8-91b7acdf4b81",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Build prompt\n",
    "template = \"\"\"Use the following pieces of context to answer the question at the end. If you don't know the answer, just say that you don't know, don't try to make up an answer. Use three sentences maximum. Keep the answer as concise as possible. Always say \"thanks for asking!\" at the end of the answer. \n",
    "{context}\n",
    "Question: {question}\n",
    "Helpful Answer:\"\"\"\n",
    "\n",
    "QA_CHAIN_PROMPT = PromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d5ceb30e-cb88-4247-aed0-cd5e563a7bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm,\n",
    "    retriever=vectordb.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs={\"prompt\": QA_CHAIN_PROMPT}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cdfefea8-8ba5-4432-a3dc-5972ab6e90c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The paper covers various topics related to language modeling, including language modeling basics, language modeling tasks, language modeling techniques, and language modeling research. It also discusses the challenges faced by LLMs in language modeling, such as the need for prompting and the importance of understanding human reasoning. The paper provides examples of how LLMs can be used to solve real-world problems, including reasoning, logic, and natural language generation.</s>'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"What are major topics for this paper?\"\n",
    "result = qa_chain.invoke({\"query\": question})\n",
    "result[\"result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37aaacaa-b67f-49de-81d7-4030e2755593",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
