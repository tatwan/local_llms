{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05004106-ebc1-47ab-a55c-a288dd554ae8",
   "metadata": {},
   "source": [
    "# Install all necessary libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca210c49-4100-447b-8d5a-42158ab68e9f",
   "metadata": {},
   "source": [
    "#### Install OpenAI, HuggingFace Transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0834704-4e24-4078-8783-e32b4ab30274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install openai transformers torch datasets -q"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17734235-7a8e-4151-8169-4c00b20514c1",
   "metadata": {},
   "source": [
    "#### Install LlamaIndex "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7f6526-4dcd-49f3-9b7e-5934b30d86e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install llama-index\n",
    "# !pip install llama-index-llms-llamafile\n",
    "# !pip install llama-index-embeddings-llamafile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f977028b-4a7f-465a-909e-3183b32307c8",
   "metadata": {},
   "source": [
    "# Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c7583d61-7018-4cd0-b633-ae1133d587c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "67698de7-7bfb-433e-9e8a-bf43a83c1047",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "    base_url=\"http://127.0.0.1:8080/v1\", = Openm\n",
    "    api_key = \"sk-no-key-required\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1dd6cfc-b04e-464c-840e-0c293ac4e7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is the ability of machines to simulate human intelligence and reasoning processes. It involves the development of computer systems that can perform tasks that require human intelligence, such as problem-solving, decision-making, and language processing. AI is a rapidly growing field that has the potential to revolutionize various industries, including healthcare, finance, and transportation.\n",
      "AI can be divided into two main categories: machine learning and deep learning. Machine learning involves the use of algorithms to learn from data, while deep learning involves the use of neural networks to simulate the structure and function of the human brain. Both types of AI have the potential to improve the efficiency and effectiveness of various industries.</s>\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"TinyLLM\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is Artificial Intelligence?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "93ee1a10-e607-4ad2-b774-f7670083a416",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletion(id='chatcmpl-JjScuVl3b4lHMo4Y1Zpli1QU9M1PxKyK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Artificial Intelligence (AI) is the ability of machines to simulate human intelligence and reasoning processes. It involves the development of computer systems that can perform tasks that require human intelligence, such as problem-solving, decision-making, and language processing. AI is a rapidly growing field that has the potential to revolutionize various industries, including healthcare, finance, and transportation.\\nAI can be divided into two main categories: machine learning and deep learning. Machine learning involves the use of algorithms to learn from data, while deep learning involves the use of neural networks to simulate the structure and function of the human brain. Both types of AI have the potential to improve the efficiency and effectiveness of various industries.</s>', refusal=None, role='assistant', function_call=None, tool_calls=None))], created=1727860708, model='TinyLLM', object='chat.completion', service_tier=None, system_fingerprint=None, usage=CompletionUsage(completion_tokens=150, prompt_tokens=49, total_tokens=199))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "8fd2528b-2375-4c75-8608-ce75c608f45c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Artificial Intelligence (AI) is the ability of machines to simulate human intelligence and reasoning processes. It involves the development of computer systems that can perform tasks that require human intelligence, such as problem-solving, decision-making, and language processing. AI is a rapidly growing field that has the potential to revolutionize various industries, including healthcare, finance, and transportation.\\nAI can be divided into two main categories: machine learning and deep learning. Machine learning involves the use of algorithms to learn from data, while deep learning involves the use of neural networks to simulate the structure and function of the human brain. Both types of AI have the potential to improve the efficiency and effectiveness of various industries.</s>', refusal=None, role='assistant', function_call=None, tool_calls=None))"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "245dae57-98d0-4bc5-be2c-aa0ce35f443f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatCompletionMessage(content='Artificial Intelligence (AI) is the ability of machines to simulate human intelligence and reasoning processes. It involves the development of computer systems that can perform tasks that require human intelligence, such as problem-solving, decision-making, and language processing. AI is a rapidly growing field that has the potential to revolutionize various industries, including healthcare, finance, and transportation.\\nAI can be divided into two main categories: machine learning and deep learning. Machine learning involves the use of algorithms to learn from data, while deep learning involves the use of neural networks to simulate the structure and function of the human brain. Both types of AI have the potential to improve the efficiency and effectiveness of various industries.</s>', refusal=None, role='assistant', function_call=None, tool_calls=None)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "70d4a5c4-71e0-4378-b81a-5b07028191bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Artificial Intelligence (AI) is the ability of machines to simulate human intelligence and reasoning processes. It involves the development of computer systems that can perform tasks that require human intelligence, such as problem-solving, decision-making, and language processing. AI is a rapidly growing field that has the potential to revolutionize various industries, including healthcare, finance, and transportation.\\nAI can be divided into two main categories: machine learning and deep learning. Machine learning involves the use of algorithms to learn from data, while deep learning involves the use of neural networks to simulate the structure and function of the human brain. Both types of AI have the potential to improve the efficiency and effectiveness of various industries.</s>'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5d9fb875-e3e5-40e4-8952-7d60ea8ad383",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artificial Intelligence (AI) is the ability of machines to simulate human intelligence and reasoning processes. It involves the development of computer systems that can perform tasks that require human intelligence, such as problem-solving, decision-making, and language processing. AI is a rapidly growing field that has the potential to revolutionize various industries, including healthcare, finance, and transportation.\n",
      "AI can be divided into two main categories: machine learning and deep learning. Machine learning involves the use of algorithms to learn from data, while deep learning involves the use of neural networks to simulate the structure and function of the human brain. Both types of AI have the potential to improve the efficiency and effectiveness of various industries.</s>\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "6d7bb72b-3d60-48f5-863a-1b11d634ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What is a Large Language Model?\"}\n",
    "  ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "cb5ae75e-0b99-47f7-b4b8-05a0dc0ea520",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model (LLM) is a type of artificial intelligence (AI) model that can generate human-like language. It is a type of neural network that can process large amounts of text data and generate natural-sounding sentences. LLMs are trained on large datasets of text, such as Wikipedia, and are capable of generating human-like language with varying degrees of accuracy. They are used in a variety of applications, including natural language processing (NLP), machine translation, and chatbots.</s>\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"TinyLLM\",\n",
    "  messages= message\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "100d9f07-853f-4249-b39b-14e66590f40b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A Large Language Model (LLM) is a type of machine learning model that can learn to generate human-like text by processing large amounts of data. LLMs can simulate the process of human language generation by analyzing vast amounts of text data and generating responses based on those insights. LLMs are widely used in natural language processing (NLP) and are critical to the development of AI-based chatbots, language translation, and other applications that require high-quality text generation.</s>\n"
     ]
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "  model=\"TinyLLM\",\n",
    "  messages= message,\n",
    "  max_tokens=200,\n",
    "  temperature=0.7\n",
    ")\n",
    "\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "099f4552-03d3-48f6-911e-c26f952fadf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "message=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": \"Write an example of a Hello World in Python\"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "50a3038e-2c65-4eab-b340-7d13ddd730b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"TinyLLM\",\n",
    "    messages=message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "6322847d-f1f6-4029-945e-d7e628242384",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here's an example of a Hello World in Python:\n",
      "\n",
      "```python\n",
      "print(\"Hello, World!\")\n",
      "```\n",
      "\n",
      "In this example, we're printing the string \"Hello, World!\" to the console.</s>\n"
     ]
    }
   ],
   "source": [
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "94eae04c-0f93-4b21-a532-ff90155a6cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "addac975-005b-47b0-abb1-d091cb2a9f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "message=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. Respond in Markdown\"},\n",
    "        {\"role\": \"user\",\n",
    "         \"content\": \"Write an example of a Hello World in Python. \"\n",
    "        }\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "03a7c46b-4e0f-42de-ac47-1759f2ebc4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"TinyLLM\",\n",
    "    messages=message\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "7c9375db-54c3-4e69-baf0-24b690e31132",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "print(\"Hello, World!\")\n",
       "```\n",
       "\n",
       "In this example, we have created a Python program that prints the string \"Hello, World!\" to the console.</s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "febaed84-9931-4beb-bd19-2a7b20267ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "# This is a Hello World program in Python\n",
       "print(\"Hello, World!\")\n",
       "```\n",
       "\n",
       "In this program, we have created a simple program that prints the string \"Hello, World!\" to the console. The `print()` function is used to output the string to the console.</s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "completion = client.chat.completions.create(\n",
    "    model=\"TinyLLM\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.Respond in markdown\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write an example of a Hello World in Python with explanation.\"\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "display(Markdown(completion.choices[0].message.content))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "25ee19d7-2650-4d44-893b-09d088807e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def responses(user_prompt):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"TinyLLM\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.Respond in markdown\"},\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": user_prompt\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "    return completion.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d8222c94-62cc-4f8b-9765-38a32242563f",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = responses(\"Write me a Hello World example in Java with explanations and steps in bullet points\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8dc2ec19-ea46-4e6d-ba6d-510ee4f2f01d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Sure, here's a Hello World example in Java with explanations and steps:\n",
       "\n",
       "```java\n",
       "public class HelloWorld {\n",
       "    public static void main(String[] args) {\n",
       "        System.out.println(\"Hello, World!\");\n",
       "    }\n",
       "}\n",
       "```\n",
       "\n",
       "1. Create a new Java project in your IDE (e.g. IntelliJ IDEA)\n",
       "2. Open the `main` class in the `HelloWorld` package\n",
       "3. Add the following code:\n",
       "   ```java\n",
       "   public class HelloWorld {\n",
       "       public static void main(String[] args) {\n",
       "           System.out.println(\"Hello, World!\");\n",
       "       }\n",
       "   }\n",
       "   ```\n",
       "4. Save the file and compile it using the `javac` command:\n",
       "   ```\n",
       "   javac -cp .:lib/junit-4.12.jar HelloWorld.java\n",
       "   ```\n",
       "5. Run the program using the `java` command:\n",
       "   ```\n",
       "   java -cp .:lib/junit-4.12.jar HelloWorld\n",
       "   ```\n",
       "6. You should see the message \"Hello, World!\" printed to the console.\n",
       "\n",
       "I hope this helps! Let me know if you have any further questions.</s>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc07e4-cb67-4ef2-a614-480ff131ec05",
   "metadata": {},
   "source": [
    "### Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4723aa14-6637-4e30-98df-342ccc5f886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.embeddings.create(\n",
    "    model='TinyLLM',\n",
    "    input=\"The cat in the hat\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "ab91be77-db8e-4ff6-8a7a-f6db1d77b58e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response.data[0].embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bf4fd331-0021-456b-a89c-7c00d1a4dbad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.5089522750931792e-05,\n",
       " 0.021073533222079277,\n",
       " -0.014772878959774971,\n",
       " -0.0008209511288441718,\n",
       " 0.015734871849417686,\n",
       " 0.014699813909828663,\n",
       " 0.010607830248773098,\n",
       " 0.017330771312117577,\n",
       " -0.0011142035946249962,\n",
       " -0.009285327047109604]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.data[0].embedding[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "05f488c1-15ff-4667-9b0c-4aa3001d1f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "q1 = client.embeddings.create(\n",
    "    model='TinyLLM',\n",
    "    input=\"What is a LLM??\"\n",
    ")\n",
    "\n",
    "q2 = client.embeddings.create(\n",
    "    model='TinyLLM',\n",
    "    input=\"What is a Large Language Model?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "dc110d03-1d02-4219-bc05-429f5944bb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.002883902518078685,\n",
       " -0.0184649545699358,\n",
       " -0.021974455565214157,\n",
       " 0.0017540018307045102,\n",
       " -0.021339841187000275,\n",
       " -0.024504896253347397,\n",
       " -0.010022232308983803,\n",
       " -0.024798454716801643,\n",
       " -0.01472487673163414,\n",
       " -0.014400114305317402,\n",
       " 0.028253769502043724,\n",
       " -0.008759178221225739,\n",
       " -0.01150496769696474,\n",
       " -0.00979495421051979,\n",
       " 0.0029542685952037573,\n",
       " -0.0020822910591959953,\n",
       " 0.017404112964868546,\n",
       " -0.008826208300888538,\n",
       " -0.02944796159863472,\n",
       " 0.011441878043115139]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1.data[0].embedding[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c23e3d0f-ee30-4929-b310-dae1df2157fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[-0.010369114577770233,\n",
       " -0.013365156948566437,\n",
       " -0.0027918058913201094,\n",
       " -0.012412614189088345,\n",
       " -0.015157658606767654,\n",
       " -0.01728396862745285,\n",
       " -0.0013681371929123998,\n",
       " -0.019303595647215843,\n",
       " -0.008755148388445377,\n",
       " -0.02654951438307762,\n",
       " 0.02182239480316639,\n",
       " 0.00059725739993155,\n",
       " 0.009518014267086983,\n",
       " 0.022850697860121727,\n",
       " 0.0008401128579862416,\n",
       " -0.011973206885159016,\n",
       " 0.02467368170619011,\n",
       " 0.006160115357488394,\n",
       " -0.04989228397607803,\n",
       " 0.01488324161618948]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q2.data[0].embedding[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "23bf0b50-75b1-448f-a5a2-2d637d2fff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Function to generate an email\n",
    "def generate_email(subject, recipient_name, additional_info):\n",
    "    \n",
    "    prompt = f\"Write a professional email to {recipient_name} with the subject '{subject}'. Include the following information: {additional_info}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"TinyLLama\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "57642de9-9d7b-4caf-89ee-f71ef9e0ed02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_writing_assistant():\n",
    "    print(\"Welcome to the Email Writing Assistant!\\n\")\n",
    "    subject = input(\"Enter the email subject: \")\n",
    "    recipient_name = input(\"Enter the recipient's name: \")\n",
    "    additional_info = input(\"Enter any additional information to include in the email: \")\n",
    "    email = generate_email(subject, recipient_name, additional_info)\n",
    "    print(f\"Email:\\n{email}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "82f724d0-973f-459b-871e-3c773eedb52b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Email Writing Assistant!\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter the email subject:  I will be out of office\n",
      "Enter the recipient's name:  Sara\n",
      "Enter any additional information to include in the email:  I need a vacation ASAP\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Email:\n",
      "Subject: I will be out of office\n",
      "\n",
      "Dear Sara,\n",
      "\n",
      "I am writing to inform you that I will be taking a short leave of absence from the office. Due to the demands of my current workload, I am in dire need of a break and I am requesting to take a vacation as soon as possible.\n",
      "\n",
      "I apologize for any inconvenience this may cause and will ensure that all my tasks are completed and my work is up to date before my departure. I will also be available by email if anything urgent arises while I am away.\n",
      "\n",
      "I would appreciate it if you could let me know as soon as possible if there are any issues or concerns regarding my request. I am looking forward to taking a well-deserved break and returning to the office refreshed and ready to tackle new challenges.\n",
      "\n",
      "Thank you for your understanding and support.\n",
      "\n",
      "Best regards,\n",
      "[Your Name]<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "email_writing_assistant()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69e547-11e4-4663-8959-44656d6c10ad",
   "metadata": {},
   "source": [
    "## LangChain Demo (Limited Demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "15f9ff1b-34e8-406f-978d-13f00fd2251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9f0a32ab-dc6b-4d75-aa78-c7c4fbbeb186",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_path = 'https://arxiv.org/pdf/2012.12931.pdf'\n",
    "pdf_loader = PyPDFLoader(file_path = pdf_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d8f76331-d882-422a-987d-a312474544c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "47"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data = pdf_loader.load_and_split()\n",
    "len(pdf_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "39ebf514-8594-4750-95c8-0fb3d7e75977",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Using Classification Datasets to Evaluate Graph Outlier\n",
      "Detection: Peculiar Observations and New Insights\n",
      "LINGXIAO ZHAO, Heinz College - Information Systems & Public Policy, Carnegie Mellon University, USA\n",
      "LEMAN AKOGLU, Heinz College - Information Systems & Public Policy, Carnegie Mellon University, USA\n",
      "It is common practice of the outlier mining community to repurpose classification datasets toward evaluating\n",
      "various detection models. To that end, often a binary classification dataset is used, where samples from\n",
      "one of the classes is designated as the ‘inlier’ samples, and the other class is substantially down-sampled\n",
      "to create the (ground-truth) ‘outlier’ samples. Graph-level outlier detection (GLOD) is rarely studied but\n",
      "has many potentially influential real-world applications. In this study, we identify an intriguing issue with\n",
      "repurposing graph classification datasets for GLOD . We find that ROC-AUC performance of the models\n",
      "changes significantly (“flips” from high to very low, even worse than random) depending on which class is\n",
      "down-sampled. Interestingly, ROC-AUCs on these two variants approximately sum to 1 and their performance\n",
      "gap is amplified with increasing propagations for a certain family of propagation based outlier detection\n",
      "models. We carefully study the graph embedding space produced by propagation based models and find\n",
      "two driving factors: (1) disparity between within-class densities which is amplified by propagation, and (2)\n",
      "overlapping support (mixing of embeddings) across classes. We also study other graph embedding methods and\n",
      "downstream outlier detectors, and find that the intriguing “performance flip” issue still widely exists but which\n",
      "version of the downsample achieves higher performance may vary. Thoughtful analysis over comprehensive\n",
      "results further deeper our understanding of the established issue.\n",
      "With this study, we aim to draw attention to this (to our knowledge) previously-unnoticed issue for the\n",
      "rarely studied GLOD problem, and specifically to the following questions: 1) Given the performance flip\n",
      "issue we identified, where one version of the downsample often yields worse-than-random performance, is it\n",
      "acppropriate to evaluate GLOD by average performance across all downsampled versions when repurposing\n",
      "graph classification datasets? 2) Considering onsistently observed performance flip issue across different graph\n",
      "embedding methods we studied, is it possible to design better graph embedding methods to to overcome the\n",
      "issue? We conclude the paper with our insights to these questions.\n",
      "1 INTRODUCTION\n",
      "Outlier detection is a critical task that finds numerous applications in healthcare, security, finance,\n",
      "etc. [ 1]. Simply put, the task is to identify observations that notably stand out within large collections\n",
      "of data so as to “arouse suspicions that [they were] generated by a different mechanism” [ 12]. One\n",
      "of the key challenges of outlier detection is that it poses an unsupervised learning problem. Due\n",
      "to the rare nature of outlier instances, combined with the laborious manual (i.e., human) labeling,\n",
      "access to benchmark datasets with sufficiently many labeled ground-truth outliers is limited.\n",
      "Motivation. Lack of labeled benchmark datasets for outlier detection is not only a challenge\n",
      "for learning, but also for the evaluation of outlier models. Even if one designs unsupervised models\n",
      "for the detection task, ground-truth labels that truly reflect the nature of outliers in a domain is\n",
      "essential for the reliable error estimation of various models. Thereby, the scarcity of representative\n",
      "Authors’ addresses: Lingxiao Zhao, lingxia1@andrew.cmu.edu, Heinz College - Information Systems & Public Policy,\n",
      "Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA, USA, 15213; Leman Akoglu, lakoglu@andrew.cmu.edu, Heinz\n",
      "College - Information Systems & Public Policy, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA, USA, 15213.\n"
     ]
    }
   ],
   "source": [
    "print(pdf_data[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085e4c02-9f26-4e7a-a8c9-2e44141fddd8",
   "metadata": {},
   "source": [
    "**CharacterTextSplitter**:\n",
    "* Tries to preserve paragraphs, sentences, and words as coherent units.\n",
    "* Can specify chunk_size, chunk_overlap, and separator.\n",
    "* Does not automatically handle very large chunks; instead, it relies on the user setting appropriate values for chunk_size and chunk_overlap.\n",
    "\n",
    "**RecursiveCharacterTextSplitter**:\n",
    "* Similar to CharacterTextSplitter, but adds recursive splitting capabilities.\n",
    "* Automatically handles very large chunks by attempting to split them according to the specified chunk_size and separator list.\n",
    "* If a chunk remains too large after the first round of splitting, it will try again with subsequent separators in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "190663c9-7873-4e8c-ba32-ca0e6c05f68a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "141"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# split [\"\\n\\n\", \"\\n\", \" \", \"\" ]\n",
    "splitterR = RecursiveCharacterTextSplitter(\n",
    "     chunk_size = 1000,\n",
    "     chunk_overlap = 0\n",
    ")\n",
    "\n",
    "pdf_data_RS = pdf_loader.load_and_split(text_splitter=splitterR)\n",
    "len(pdf_data_RS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae32def2-1cf7-49c9-9d0a-5fee61503fb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Using Classification Datasets to Evaluate Graph Outlier\n",
      "Detection: Peculiar Observations and New Insights\n",
      "LINGXIAO ZHAO, Heinz College - Information Systems & Public Policy, Carnegie Mellon University, USA\n",
      "LEMAN AKOGLU, Heinz College - Information Systems & Public Policy, Carnegie Mellon University, USA\n",
      "It is common practice of the outlier mining community to repurpose classification datasets toward evaluating\n",
      "various detection models. To that end, often a binary classification dataset is used, where samples from\n",
      "one of the classes is designated as the ‘inlier’ samples, and the other class is substantially down-sampled\n",
      "to create the (ground-truth) ‘outlier’ samples. Graph-level outlier detection (GLOD) is rarely studied but\n",
      "has many potentially influential real-world applications. In this study, we identify an intriguing issue with\n",
      "repurposing graph classification datasets for GLOD . We find that ROC-AUC performance of the models\n"
     ]
    }
   ],
   "source": [
    "print(pdf_data_RS[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "757af94f-54d2-453b-b6cb-ceb3f90b214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.summarize import load_summarize_chain\n",
    "from langchain_community.llms.llamafile import Llamafile\n",
    "\n",
    "# Initialize Llamafile\n",
    "llm = Llamafile(temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "4612e40f-c233-4442-a522-2566ad86f905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new StuffDocumentsChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "\n",
      "Write a summary that highlights the main ideas in 3 bullet points of the following:\n",
      "\n",
      "\n",
      "\"On Using Classification Datasets to Evaluate Graph Outlier\n",
      "Detection: Peculiar Observations and New Insights\n",
      "LINGXIAO ZHAO, Heinz College - Information Systems & Public Policy, Carnegie Mellon University, USA\n",
      "LEMAN AKOGLU, Heinz College - Information Systems & Public Policy, Carnegie Mellon University, USA\n",
      "It is common practice of the outlier mining community to repurpose classification datasets toward evaluating\n",
      "various detection models. To that end, often a binary classification dataset is used, where samples from\n",
      "one of the classes is designated as the ‘inlier’ samples, and the other class is substantially down-sampled\n",
      "to create the (ground-truth) ‘outlier’ samples. Graph-level outlier detection (GLOD) is rarely studied but\n",
      "has many potentially influential real-world applications. In this study, we identify an intriguing issue with\n",
      "repurposing graph classification datasets for GLOD . We find that ROC-AUC performance of the models\n",
      "\n",
      "changes significantly (“flips” from high to very low, even worse than random) depending on which class is\n",
      "down-sampled. Interestingly, ROC-AUCs on these two variants approximately sum to 1 and their performance\n",
      "gap is amplified with increasing propagations for a certain family of propagation based outlier detection\n",
      "models. We carefully study the graph embedding space produced by propagation based models and find\n",
      "two driving factors: (1) disparity between within-class densities which is amplified by propagation, and (2)\n",
      "overlapping support (mixing of embeddings) across classes. We also study other graph embedding methods and\n",
      "downstream outlier detectors, and find that the intriguing “performance flip” issue still widely exists but which\n",
      "version of the downsample achieves higher performance may vary. Thoughtful analysis over comprehensive\n",
      "results further deeper our understanding of the established issue.\n",
      "\n",
      "With this study, we aim to draw attention to this (to our knowledge) previously-unnoticed issue for the\n",
      "rarely studied GLOD problem, and specifically to the following questions: 1) Given the performance flip\n",
      "issue we identified, where one version of the downsample often yields worse-than-random performance, is it\n",
      "acppropriate to evaluate GLOD by average performance across all downsampled versions when repurposing\n",
      "graph classification datasets? 2) Considering onsistently observed performance flip issue across different graph\n",
      "embedding methods we studied, is it possible to design better graph embedding methods to to overcome the\n",
      "issue? We conclude the paper with our insights to these questions.\n",
      "1 INTRODUCTION\n",
      "Outlier detection is a critical task that finds numerous applications in healthcare, security, finance,\n",
      "etc. [ 1]. Simply put, the task is to identify observations that notably stand out within large collections\n",
      "\n",
      "of data so as to “arouse suspicions that [they were] generated by a different mechanism” [ 12]. One\n",
      "of the key challenges of outlier detection is that it poses an unsupervised learning problem. Due\n",
      "to the rare nature of outlier instances, combined with the laborious manual (i.e., human) labeling,\n",
      "access to benchmark datasets with sufficiently many labeled ground-truth outliers is limited.\n",
      "Motivation. Lack of labeled benchmark datasets for outlier detection is not only a challenge\n",
      "for learning, but also for the evaluation of outlier models. Even if one designs unsupervised models\n",
      "for the detection task, ground-truth labels that truly reflect the nature of outliers in a domain is\n",
      "essential for the reliable error estimation of various models. Thereby, the scarcity of representative\n",
      "Authors’ addresses: Lingxiao Zhao, lingxia1@andrew.cmu.edu, Heinz College - Information Systems & Public Policy,\n",
      "\n",
      "Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA, USA, 15213; Leman Akoglu, lakoglu@andrew.cmu.edu, Heinz\n",
      "College - Information Systems & Public Policy, Carnegie Mellon University, 5000 Forbes Ave, Pittsburgh, PA, USA, 15213.\n",
      "Permission to make digital or hard copies of part or all of this work for personal or classroom use is granted without fee\n",
      "provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and\n",
      "the full citation on the first page. Copyrights for third-party components of this work must be honored. For all other uses,\n",
      "contact the owner/author(s).\n",
      "©2021 Copyright held by the owner/author(s).\n",
      "1arXiv:2012.12931v3  [cs.LG]  18 May 2021\n",
      "\n",
      "Lingxiao Zhao and Leman Akoglu\n",
      "labeled outliers in real-world datasets has motivated a couple of strategies for building benchmark\n",
      "datasets, mainly for evaluation.\n",
      "One strategy is to inject realistic yet synthetic outliers into real-world datasets via simulation. For\n",
      "example, in fraud detection applications, one could simulate activities that reflect malicious schemes\n",
      "known to domain experts in order to obtain positive (i.e., anomalous) observations. Emmott et al.\n",
      "[7,8] present a systematic in-depth study on this subject. This approach is typically criticized for\n",
      "a couple of reasons. First, the simulated outliers are limited to the known anomalous behaviors\n",
      "and may not comprehensively reflect the outliers in the wild. Second, this type of approach may\n",
      "create an environment fertile to “leakage”, where the outliers may be simulated in a biased way\n",
      "that aligns with how the detection model under evaluation works.\n",
      "\n",
      "An alternative strategy to artificial outlier injection is to repurpose classification datasets so\n",
      "as to work with only real-world samples. (See [ 4] and citations therein.) A common practice is\n",
      "to use binary classification datasets, where samples from one of the classes (typically the one\n",
      "with the larger number of samples) is treated as the ‘inlier’ samples, and the other class is down-\n",
      "sampled (to a desired rate) to constitute the ‘outlier’ samples. This procedure conforms with the\n",
      "notion of outlierness as characterized by Hawkins [ 12], in that the outliers are drawn from a data\n",
      "distribution (i.e., class) that is different from that generating the inliers. In their in-depth evaluation\n",
      "of unsupervised outlier detection models, Campos et al. [4] mainly adopt this strategy.\n",
      "This paper. In this study we scrutinize this latter strategy, and pose the following questions:\n",
      "Should one use classification datasets for evaluating outlier detection models? What issues should one\n",
      "\n",
      "be aware of in designing benchmark datasets in this manner? Specifically, we study this issue in\n",
      "the context of outlier detection in graph databases , where given a collection of graphs, the task\n",
      "is to identify the outlier graphs that stand out. Graph data is widespread in finance, health care,\n",
      "cybersecurity, fault monitoring, etc. where the outlier detection task finds a long list of applications\n",
      "such as identifying rare transaction graphs [ 27], command flow graphs [ 20], and human poses [ 21],\n",
      "fake news [23], traffic events [11], buggy software [17], money laundering [39], and so on.\n",
      "Before delving into details, we start by illustrating the intriguing “performance flip” issue\n",
      "empirically. Table 1 (See Sec. 3.1) shows the ROC-AUC performances of three graph embedding\n",
      "based outlier detectors based on four binary graph classification datasets (Additional results on\n",
      "more datasets, and using more graph embedding methods is available in Tables 4&5 ). Each dataset\n",
      "\n",
      "has two variants, each corresponding to one of the classes down-sampled as outlier. The difference\n",
      "in performances between the two variants is striking, consistently across models on most (although\n",
      "not all) datasets.\n",
      "Related work. To the best of our knowledge, the performance flip issue has not been identified\n",
      "by any prior work on outlier mining, with the exception of work by Swersky et al. [35] which\n",
      "document similar ROC-AUC flip behavior on several datasets, however the authors have not\n",
      "recognized explicitly. Campos et al. [4] state that “random downsampling often leads to great\n",
      "variation in the nature of the outliers produced” and that “observations based on downsampling\n",
      "can vary considerably from sample to sample”, based on which they repeat their down-sampling\n",
      "procedure 10 times per dataset “to mitigate the impact of randomization”. This, however, points\n",
      "to an orthogonal issue as it pertains to down-sampling after deciding (i.e. fixing) which class to\n",
      "\n",
      "down-sample. Repurposing classification datasets for evaluation of clustering has been questioned\n",
      "by Färber et al. [9], which alludes to the potential misalignment between the semantics of data\n",
      "clusters and class labels. Our study points to an issue orthogonal to semantics.\n",
      "Contributions. Through extensive analysis, our study aims to (1) illustrate the issues with\n",
      "using graph classification datasets for creating outlier benchmarks for model evaluation, (2) identify\n",
      "the leading factors behind these issues, (3) propose concrete measures to quantify these factors and\n",
      "explain their possible driving mechanisms with a focus on propagation-based graph embedding\n",
      "2\"\n",
      "\n",
      "\n",
      "SUMMARY IN BULLETS:\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"\n",
    "\n",
    "Write a summary that highlights the main ideas in 3 bullet points of the following:\n",
    "\n",
    "\n",
    "\"{text}\"\n",
    "\n",
    "\n",
    "SUMMARY IN BULLETS:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = load_summarize_chain(\n",
    "    llm=llm,\n",
    "    chain_type='stuff',\n",
    "    prompt=prompt,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "results = chain.invoke(pdf_data_RS[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9ff5fa84-1bad-43a3-8a87-19d976078707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_documents', 'output_text'])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2f57171e-4fc2-4a8a-9531-fd58fd8ae47d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "• The study identifies an issue with repurposing graph classification datasets for evaluating Graph-Level Outlier Detection (GLOD) models, where the performance of the models changes significantly depending on which class is down-sampled.\n",
      "• The authors find that this \"performance flip\" issue is due to two driving factors: disparity between within-class densities amplified by propagation and overlapping support across classes in the graph embedding space produced by propagation-based outlier detection models.\n",
      "• The study highlights the importance of considering these issues when evaluating GLOD models using classification datasets, and proposes measures to quantify and explain the driving mechanisms behind this performance flip issue.<|eot_id|>\n"
     ]
    }
   ],
   "source": [
    "print(results['output_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "333161a4-e3a7-485d-a7e1-01b51eae529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define prompt\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", \"Write a concise summary of the following:\\\\n\\\\n{context}\")]\n",
    ")\n",
    "\n",
    "# Instantiate chain\n",
    "chain = create_stuff_documents_chain(llm, prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "f792d784-dfd4-4d83-b553-c9d0509cdfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Invoke chain\n",
    "# result = chain.invoke({\"context\": pdf_data_RS[0:10]})\n",
    "# print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44bb8961-81fe-4fec-80d5-882a82a080bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for token in chain.stream({\"context\": pdf_data_RS[0:5]}):\n",
    "#     print(token, end=\"|\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263a445-aa5f-420b-8181-9b78fdbf3af3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:llms]",
   "language": "python",
   "name": "conda-env-llms-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
